{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30e8b72",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# IMPORTS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b86bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.dataframe td { white-space: nowrap; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# no text wrapping\n",
    "display(HTML(\"<style>.dataframe td { white-space: nowrap; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b99b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframes\n",
    "df_SD = pd.read_pickle('df_SD.pickle')\n",
    "df_FD = pd.read_pickle('df_FD.pickle')\n",
    "df_LF = pd.read_pickle('df_LF.pickle')\n",
    "df_Site = pd.read_pickle('df_Site.pickle')\n",
    "df_TrapSupervisors = pd.read_pickle('df_TrapSupervisors.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975904c",
   "metadata": {},
   "source": [
    "### Helper Function to UPDATE ID to Match Updated DATETIME and SITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e7c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_id(row):\n",
    "    \"\"\"only run before disambiguating month portion of ids for FD and LF\"\"\"\n",
    "    return str(row.id)[0:4] + str(row.DATETIME.month).rjust(2,'0') + str(row.DATETIME.day).rjust(2, '0') + str(row.SITE1).rjust(2, '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8832f",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# FISH DETAILS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e121f",
   "metadata": {},
   "source": [
    "## Combine Age 2 and Age 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc43f74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if age2 and age3 occur at the same time\n",
    "(\n",
    "    df_FD[df_FD['Ager_2'].notnull() & df_FD['Ager_3'].notnull()].shape[0],\n",
    "    df_FD[df_FD['AGE_2'].notnull() & df_FD['AGE_3'].notnull()].shape[0],\n",
    "    df_FD[df_FD['FSP_2'].notnull() & df_FD['FSP_3'].notnull()].shape[0], \n",
    "    df_FD[df_FD['Comments_2'].notnull() & df_FD['Comments_3'].notnull()].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a465887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 2 columns\n",
    "df_FD[df_FD.Ager_2.notnull() | df_FD.AGE_2.notnull() | df_FD.FSP_2.notnull() | df_FD.Comments_2.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5656122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2339"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 3 columns\n",
    "df_FD[df_FD.Ager_3.notnull() | df_FD.AGE_3.notnull() | df_FD.FSP_3.notnull() | df_FD.Comments_3.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed7b31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine aging 2 and aging 3 into one set of data\n",
    "df_FD['Ager_2'] = df_FD['Ager_2'].fillna(df_FD['Ager_3'])\n",
    "df_FD['AGE_2'] = df_FD['AGE_2'].fillna(df_FD['AGE_3'])\n",
    "df_FD['FSP_2'] = df_FD['FSP_2'].fillna(df_FD['FSP_3'])\n",
    "df_FD['Comments_2'] = df_FD['Comments_2'].fillna(df_FD['Comments_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be03976a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4022"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 2 columns\n",
    "df_FD[df_FD.Ager_2.notnull() | df_FD.AGE_2.notnull() | df_FD.FSP_2.notnull() | df_FD.Comments_2.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717dc86",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e1023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if site is changed away from SITE1, update id to match\n",
    "\n",
    "# df_FD.loc[df_FD.FLAG_SITE==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e5739",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD: leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bcc7d",
   "metadata": {},
   "source": [
    "## FLAG_SEX: B and A? -> null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c65bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.FLAG_SEX==True, 'SEX'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fdb4666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'U', nan], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FD.loc[:, 'SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4317182",
   "metadata": {},
   "source": [
    "## FLAG_MATURITY: 44=4, 0=null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df0bc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.MATURITY==44, 'MATURITY'] = 4\n",
    "df_FD.loc[df_FD.MATURITY==0, 'MATURITY'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8a966",
   "metadata": {},
   "source": [
    "## FLAG_FSP_1: 33=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "466cbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.FSP_1==33, 'FSP_1'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873989fb",
   "metadata": {},
   "source": [
    "## FLAG_FL_STD: 10x off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b1563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34923   261.000\n",
       "34924   218.000\n",
       "34925   260.000\n",
       "34926   283.000\n",
       "34927   219.000\n",
       "          ...  \n",
       "35504   227.000\n",
       "35505   236.000\n",
       "35506   208.000\n",
       "35507   228.000\n",
       "35508   202.000\n",
       "Name: FL_STD, Length: 264, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.FLAG_FL_STD==True, 'FL_STD'] *= 10\n",
    "df_FD.loc[df_FD.FLAG_FL_STD==True, 'FL_STD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d475cf0",
   "metadata": {},
   "source": [
    "## FLAG_FL_WET_FROZEN: 5 typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca0ebd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONDITION</th>\n",
       "      <th>FL_WET</th>\n",
       "      <th>FL_FROZEN</th>\n",
       "      <th>FL_STD</th>\n",
       "      <th>fish_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35249</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>259</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35392</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35478</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35479</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35507</th>\n",
       "      <td>Frozen</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CONDITION  FL_WET  FL_FROZEN  FL_STD  fish_length\n",
       "35249    Frozen    <NA>        259     NaN          259\n",
       "35392    Frozen    <NA>        251     NaN          251\n",
       "35478    Frozen    <NA>        228     NaN          228\n",
       "35479    Frozen    <NA>        200     NaN          200\n",
       "35507    Frozen    <NA>        204     NaN          204"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STD doesn't need to be converted here, it will be standardised in dm_apps from the frozen length and frozen condition\n",
    "df_FD.loc[df_FD.FLAG_FL_WET_FROZEN==True, ['FL_WET', 'FL_STD']] = np.nan\n",
    "df_FD.loc[df_FD.FLAG_FL_WET_FROZEN==True, 'FL_FROZEN'] = [259, 251, 228, 200, 204]\n",
    "df_FD.loc[df_FD.FLAG_FL_WET_FROZEN==True, 'fish_length'] = [259, 251, 228, 200, 204]\n",
    "df_FD.loc[df_FD.FLAG_FL_WET_FROZEN==True, ['CONDITION', 'FL_WET', 'FL_FROZEN', 'FL_STD', 'fish_length']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23cd7a",
   "metadata": {},
   "source": [
    "## FLAG_WEIGHT_OUTLIER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f865c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724      519.000\n",
       "735      539.000\n",
       "956      501.000\n",
       "1777     512.000\n",
       "5477     503.000\n",
       "35212   1934.000\n",
       "Name: WEIGHT, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FD.loc[df_FD.FLAG_WEIGHT_OUTLIER==True, 'WEIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78cb6f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "724     519.000\n",
       "735     539.000\n",
       "956     501.000\n",
       "1777    512.000\n",
       "5477    503.000\n",
       "35212       NaN\n",
       "Name: WEIGHT, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.WEIGHT>1000, 'WEIGHT'] = np.nan\n",
    "df_FD.loc[df_FD.FLAG_WEIGHT_OUTLIER==True, 'WEIGHT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3f6bc",
   "metadata": {},
   "source": [
    "## FLAG_GONAD_OUTLIER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f458e672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5790    NaN\n",
       "13647   NaN\n",
       "23059   NaN\n",
       "23295   NaN\n",
       "24542   NaN\n",
       "26462   NaN\n",
       "33026   NaN\n",
       "Name: GONAD_WEIGHT, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.FLAG_GONAD_OUTLIER==True, 'GONAD_WEIGHT'] = np.nan\n",
    "df_FD.loc[df_FD.FLAG_GONAD_OUTLIER==True, 'GONAD_WEIGHT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb1883",
   "metadata": {},
   "source": [
    "## FLAG_MULTIPLE_SAMPLE_POSSIBILITIES and FLAG_MISNUMBERED_FISH_DETAILS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1302a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_MULTIPLE_SAMPLE_POSSIBILITIES==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0fb582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_MISNUMBERED_FISH_DETAILS==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fb32c",
   "metadata": {},
   "source": [
    "## FLAG_LEN_WT_RATIO_OUTLIER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bb7055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_LEN_WT_RATIO_OUTLIER==True, ['FL_STD', 'WEIGHT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebe772",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# LENGTH FREQUENCIES\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609f406",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b825f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if site is changed away from SITE1, update id to match\n",
    "\n",
    "# df_LF.loc[df_LF.FLAG_SITE==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b544d26",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD: leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc70a9",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# SAMPLES\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d407fa",
   "metadata": {},
   "source": [
    "## FLAG_DATETIME: null datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d4bd35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if date is changed, update id to match\n",
    "\n",
    "# df_SD.loc[df_SD.FLAG_DATETIME==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d66316",
   "metadata": {},
   "source": [
    "## FLAG_HOURS_FISHED: hours_fished = \"maximum \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "250e0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13667    18\n",
       "13674    18\n",
       "13682    18\n",
       "13691    18\n",
       "13702    18\n",
       "13713    18\n",
       "13724    18\n",
       "13736    18\n",
       "13749    18\n",
       "13759    18\n",
       "13771    18\n",
       "13782    18\n",
       "13794    18\n",
       "13807    18\n",
       "13820    18\n",
       "13832    18\n",
       "13844    18\n",
       "13857    18\n",
       "13870    18\n",
       "13881    18\n",
       "13893    18\n",
       "13905    18\n",
       "13918    18\n",
       "13931    18\n",
       "13943    18\n",
       "13955    18\n",
       "13966    18\n",
       "13976    18\n",
       "Name: hours_fished, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_SD.loc[df_SD.FLAG_HOURS_FISHED==True, 'hours_fished'] = 18\n",
    "df_SD.loc[df_SD.FLAG_HOURS_FISHED==True, 'hours_fished']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ce6f3",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "def530ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6019    1A,8\n",
       "6028    1A,8\n",
       "6037    1A,8\n",
       "6046    1A,8\n",
       "6055    1A,8\n",
       "6064    1A,8\n",
       "6073    1A,8\n",
       "6081    1A,8\n",
       "6089    1A,8\n",
       "6097    1A,8\n",
       "6106    1A,8\n",
       "6115    1A,8\n",
       "6124    1A,8\n",
       "6132    1A,8\n",
       "6141    1A,8\n",
       "6150    1A,8\n",
       "6158    1A,8\n",
       "6167    1A,8\n",
       "6183    1A,8\n",
       "6192    1A,8\n",
       "6201    1A,8\n",
       "6209    1A,8\n",
       "6217    1A,8\n",
       "Name: SITE_NO, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: if site is updated, update id to match\n",
    "\n",
    "# these are currently importing as 1A\n",
    "df_SD.loc[df_SD.FLAG_SITE==True, 'SITE_NO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec34f58",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD_DISCREPANCIES: FD and LF inconsistent\n",
    "#### SAMPLES, LENGTH FREQUENCIES, and FISH DETAILS all flagged\n",
    "* The samples will be where the AM PM data will be stored, so they are the only updates needed, outside of ghost samples, which can be updated as information becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cde8ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIST</th>\n",
       "      <th>RIVER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>code</th>\n",
       "      <th>GEAR</th>\n",
       "      <th>SITE_NO</th>\n",
       "      <th>no_nets</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>Week</th>\n",
       "      <th>catch_lbs</th>\n",
       "      <th>catch_kg</th>\n",
       "      <th>hours_fished</th>\n",
       "      <th>zone</th>\n",
       "      <th>last_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>bycatch_sbass</th>\n",
       "      <th>bycatch_shad</th>\n",
       "      <th>bycatch_other</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>SITE1</th>\n",
       "      <th>SITE2</th>\n",
       "      <th>remarks</th>\n",
       "      <th>id</th>\n",
       "      <th>total_fish_preserved</th>\n",
       "      <th>total_fish_measured</th>\n",
       "      <th>AM_PM_PERIOD</th>\n",
       "      <th>wt_lbs</th>\n",
       "      <th>FLAG_DATETIME</th>\n",
       "      <th>FLAG_HOURS_FISHED</th>\n",
       "      <th>FLAG_SITE</th>\n",
       "      <th>FLAG_AM_PM_PERIOD_DISCREPANCIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Daniel Stewart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>499.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper</td>\n",
       "      <td>STEWART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993051333</td>\n",
       "      <td>34.000</td>\n",
       "      <td>210.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>115.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8224</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Pierre Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>500.000</td>\n",
       "      <td>226.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lower</td>\n",
       "      <td>Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-06-15</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001061526</td>\n",
       "      <td>51.000</td>\n",
       "      <td>283.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>136.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10432</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Pierre Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9600.000</td>\n",
       "      <td>4354.500</td>\n",
       "      <td>8</td>\n",
       "      <td>lower</td>\n",
       "      <td>Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-02</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007060226</td>\n",
       "      <td>32.000</td>\n",
       "      <td>290.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>130.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Donelda M Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>450.000</td>\n",
       "      <td>204.100</td>\n",
       "      <td>7</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>47</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014061047</td>\n",
       "      <td>38.000</td>\n",
       "      <td>246.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>89.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DIST   RIVER              NAME code  GEAR SITE_NO no_nets  YEAR  MM  \\\n",
       "5108      2  SWMARG    Daniel Stewart  NaN    81      33     NaN  1993   5   \n",
       "8224      2  SWMARG   Pierre Chiasson  NaN    81      26       1  2001   6   \n",
       "10432     2  SWMARG   Pierre Chiasson  NaN    81      26       1  2007   6   \n",
       "13498     2  SWMARG  Donelda M Gillis  NaN    81      47       1  2014   6   \n",
       "\n",
       "       DD  Week  catch_lbs  catch_kg hours_fished   zone last_name comments  \\\n",
       "5108   13     3   1100.000   499.000          NaN  upper   STEWART      NaN   \n",
       "8224   15     7    500.000   226.800          NaN  lower  Chiasson      NaN   \n",
       "10432   2     5   9600.000  4354.500            8  lower  Chiasson      NaN   \n",
       "13498  10     7    450.000   204.100            7  upper    Gillis      NaN   \n",
       "\n",
       "       bycatch_sbass  bycatch_shad bycatch_other   DATETIME  SITE1 SITE2  \\\n",
       "5108             NaN           NaN           NaN 1993-05-13     33  <NA>   \n",
       "8224             NaN           NaN           NaN 2001-06-15     26  <NA>   \n",
       "10432            NaN           NaN           NaN 2007-06-02     26  <NA>   \n",
       "13498            NaN           NaN           NaN 2014-06-10     47  <NA>   \n",
       "\n",
       "      remarks          id  total_fish_preserved  total_fish_measured  \\\n",
       "5108      NaN  1993051333                34.000              210.000   \n",
       "8224      NaN  2001061526                51.000              283.000   \n",
       "10432     NaN  2007060226                32.000              290.000   \n",
       "13498     NaN  2014061047                38.000              246.000   \n",
       "\n",
       "      AM_PM_PERIOD  wt_lbs FLAG_DATETIME FLAG_HOURS_FISHED FLAG_SITE  \\\n",
       "5108            AM 115.000           NaN               NaN       NaN   \n",
       "8224            AM 136.000           NaN               NaN       NaN   \n",
       "10432           AM 130.000           NaN               NaN       NaN   \n",
       "13498           AM  89.000           NaN               NaN       NaN   \n",
       "\n",
       "      FLAG_AM_PM_PERIOD_DISCREPANCIES  \n",
       "5108                             True  \n",
       "8224                             True  \n",
       "10432                            True  \n",
       "13498                            True  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SD.loc[df_SD.FLAG_AM_PM_PERIOD_DISCREPANCIES==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2699c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_AM_PM_PERIOD_DISCREPANCIES==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "499e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LF.loc[df_LF.FLAG_AM_PM_PERIOD_DISCREPANCIES==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395135c",
   "metadata": {},
   "source": [
    "## FLAG_NO_MATCHING_SAMPLE: no SAMPLE matching LF and/or FD\n",
    "* these will end up being matched with ghost samples (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d9f28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_NO_MATCHING_SAMPLE==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96fb1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LF.loc[df_LF.FLAG_NO_MATCHING_SAMPLE==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaeebd6",
   "metadata": {},
   "source": [
    "## MAKE GHOST SAMPLES\n",
    "### for unmatched fish details and length frequencies\n",
    "### NOTE:\n",
    "Some ambiguous length frequencies and fish details match with eachother. However, we do not know which sample and length frequency are from the same sample. Therefore, we should make sure none of the ambiguous entries ever match automatically, and they are matched manually (eventually) in dm_apps, once that feature is implemented.\n",
    "\n",
    "Although there are no ambiguous samples that match with length frequencies or fish details, just for throroughness, we should revise id to avoid this possibility as well. \n",
    "\n",
    "Therefore, we will arbitrarily add 20 to months in ids of ambiguous fish details, and 40 to months in ids of ambiguous length frequencies. These numbers have no possibility to match a false positive, and they still uniquely identify their date and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a985a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to disambiguate ids, add 20 to all months for FD with id>2024000000, add 40 to all months for LF with id>2024000000\n",
    "\n",
    "# these were matched using period, and corroborated using site notes and visual inspection\n",
    "matched_period = [\n",
    "    2998050105, 3000060726, 3000060926, 3001051605, 3009052026, 3009052226, 3010051126, 3010051926, 3010052726, \n",
    "    4000060726, 4000060926, 4001051605, 4009052026, 4009052226, 4010051126, 4010051926, 4010052726\n",
    "]\n",
    "\n",
    "df_FD.loc[(df_FD.id>2024000000) & (~df_FD.id.isin(matched_period)), 'id'] += 200000\n",
    "df_LF.loc[(df_LF.id>2024000000) & (~df_LF.id.isin(matched_period)), 'id'] += 400000\n",
    "\n",
    "# dubious matches - CONFIRM\n",
    "disambiguate_dubious_id_matches = False  ### CONFIRM ###\n",
    "# in general these matches look good, but they have matches like 1 ~ 1,8 ~ 1,8 (not exact matches, but the first entry always matches)\n",
    "# either we can imported matched and include notes, or disambiguate and match manually later\n",
    "df_ambiguous_match_notes = pd.read_pickle('df_ambiguous_match_notes.pickle')\n",
    "if disambiguate_dubious_id_matches:\n",
    "    df_FD.loc[df_FD.id.isin(df_ambiguous_match_notes.id), 'id'] += 200000\n",
    "    df_LF.loc[df_LF.id.isin(df_ambiguous_match_notes.id), 'id'] += 400000\n",
    "\n",
    "# verified samples are all sample ids before creating ghost samples\n",
    "verified_samples = set(df_SD.id)\n",
    "\n",
    "# temporarily add remarks to df_LF in order to note site\n",
    "df_LF['remarks'] = 'Site: ' + df_LF['site'].fillna('None')\n",
    "\n",
    "# JOIN FD and LF without an SD match, and combine remarks, date, and site\n",
    "temp = pd.merge(\n",
    "    df_LF[~df_LF.id.isin(df_SD.id)].drop_duplicates('id')[['id', 'DATETIME', 'SITE1', 'remarks']], \n",
    "    df_FD[~df_FD.id.isin(df_SD.id)].drop_duplicates('id')[['id', 'DATETIME', 'SITE1', 'remarks']],\n",
    "    on='id',\n",
    "    how='outer'\n",
    ").reset_index(drop=True)\n",
    "temp.loc[temp.remarks_x.isnull() | temp.remarks_x.isnull(), 'remarks'] = temp['remarks_x'].fillna('') + temp['remarks_y'].fillna('')\n",
    "temp.loc[temp.remarks_x.notnull() & temp.remarks_x.notnull(), 'remarks'] = temp['remarks_x'].fillna('') + '; ' + temp['remarks_y'].fillna('') # semicolon between if both exist\n",
    "temp['DATETIME'] = temp['DATETIME_x'].fillna(temp['DATETIME_y'])\n",
    "temp['SITE1'] = temp['SITE1_x'].fillna(temp['SITE1_y'])\n",
    "temp = temp[['id', 'DATETIME', 'SITE1', 'remarks']]\n",
    "\n",
    "# concatenate to the bottom of the df_SD dataframe\n",
    "df_SD = pd.concat([\n",
    "    df_SD, \n",
    "    temp\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# remove remarks from df_LF, not needed for df_LF\n",
    "df_LF.drop('remarks', axis=1)\n",
    "\n",
    "# add a Flag to indicate ghost samples for import\n",
    "df_SD.loc[~df_SD.id.isin(verified_samples), 'FLAG_GHOST_SAMPLE'] = True\n",
    "\n",
    "# add remarks about ghost samples\n",
    "df_SD.loc[~df_SD.id.isin(verified_samples), 'remarks'] += '; GHOST SAMPLE: created to match with unmatched Fish Details and/or Length Frequencies'\n",
    "\n",
    "# either way, add  notes to samples with dubious matches\n",
    "for i, row in df_SD[df_SD.id.isin(df_ambiguous_match_notes.id)].iterrows():\n",
    "    current_id = row['id']\n",
    "    if df_SD.loc[df_SD.id==current_id, 'remarks'].isnull().any():\n",
    "        df_SD.loc[df_SD.id==current_id, 'remarks'] = df_ambiguous_match_notes.loc[df_ambiguous_match_notes.id==current_id, 'SITE_AMBIGUITIES'].values[0]\n",
    "    else:\n",
    "        df_SD.loc[df_SD.id==current_id, 'remarks'] += '; ' + df_ambiguous_match_notes.loc[df_ambiguous_match_notes.id==current_id, 'SITE_AMBIGUITIES'].values[0]\n",
    "    df_SD.loc[df_SD.id==current_id, 'FLAG_AMBIGUOUS_MATCH'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acb08e",
   "metadata": {},
   "source": [
    "## REMERGE JOINED DATA\n",
    "(previously merged without ghost samples, remerge with ghost data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c25f0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop previously merged columns (to be re-merged)\n",
    "df_SD = df_SD.drop(['total_fish_preserved', 'total_fish_measured', 'AM_PM_PERIOD', 'wt_lbs'], axis=1)\n",
    "\n",
    "# JOIN with Fish Details table to get total_fish_preserved\n",
    "# NOTE: this is an estimate, assuming all fish details are accounted for. This is the best information available\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    pd.merge(df_SD, df_FD, on='id').groupby('id').count()['FISH_NO'].reset_index(),\n",
    "    on='id',\n",
    "    how='left'\n",
    ").rename({'FISH_NO':'total_fish_preserved'}, axis=1)\n",
    "\n",
    "# JOIN with Length Frequencies table to get total_fish_measured\n",
    "# NOTE: this is an estimate, assuming all length frequencies are accounted for. This is the best information available\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    pd.merge(df_SD, df_LF, on='id').groupby('id').sum()['freq'].reset_index(),\n",
    "    on='id',\n",
    "    how='left'\n",
    ").rename({'freq':'total_fish_measured'}, axis=1)\n",
    "\n",
    "# # JOIN with Fish Details and Length Frequencies to get AM_PM_PERIOD \n",
    "# # NOTE: discrepancies flagged between Length Frequencies and Fish Details\n",
    "df_period = pd.merge(\n",
    "    df_FD[df_FD.PERIOD.notnull()].groupby('id').first().reset_index()[['id', 'PERIOD']],\n",
    "    df_LF[df_LF.period.notnull()].groupby('id').first().reset_index()[['id', 'period']], \n",
    "    on='id',\n",
    "    how='outer'\n",
    ")\n",
    "df_period['AM_PM_PERIOD'] = df_period['PERIOD'].fillna(df_period['period'])\n",
    "\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    df_period[['id', 'AM_PM_PERIOD']],\n",
    "    on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# JOIN with Length Frequency table to get sample weight\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    df_LF[['id', 'wt_lbs']],\n",
    "    on='id', \n",
    "    how='left'  # all samples \n",
    ").drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931fc791",
   "metadata": {},
   "source": [
    "# Fix Datetime Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f1d4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some times merged into DATETIME from other df via ghost samples () \n",
    "# reduce to date and AM / PM period\n",
    "df_SD['DATETIME'] = pd.to_datetime(df_SD['DATETIME'].dt.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e181a0",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# LF Grouped\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121c4a2",
   "metadata": {},
   "source": [
    "## Recreate df_LF_grouped with new ambiguous ids for LF entries (+40 to month if ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5237e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by length bins, include only imported columns \n",
    "df_LF_grouped = df_LF.groupby(['id', 'length_bin_id']).sum('freq').reset_index()[['freq', 'length_bin_id', 'id']].rename({\n",
    "    'freq': 'count', \n",
    "    'length_bin_id': 'length_bin_id', \n",
    "    'id': 'sample_id'\n",
    "}, axis=1).reset_index(drop=True)[['sample_id', 'length_bin_id', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78673ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambiguous entries, month bit (+40 to disambiguate)\n",
    "min([int(str(x)[4:6]) for x in list(df_LF_grouped[df_LF_grouped.sample_id>2024000000].sample_id.unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fdd7984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular entries, month bit\n",
    "max([int(str(x)[4:6]) for x in list(df_LF_grouped[df_LF_grouped.sample_id<2024000000].sample_id.unique())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7933b523",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# COMMENTS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a44efc",
   "metadata": {},
   "source": [
    "CONVERT E.MACFARLANE, Eric Mac, Eric MacFarlane, J McFarlane to John Eric MacFarlane.\n",
    "\n",
    "JA Coady keep as is\n",
    "\n",
    "Multiple sites, keep as is. \n",
    "\n",
    "I see 118 samples from 1989 that are associated with ‘blank’. Can you convert ‘blank’ to Unknown and upload."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a41240",
   "metadata": {},
   "source": [
    "#### based on the comment: 93 and 92 are both 'John Eric MacFarlane' - should be added to sites table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "767b2a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append these and update the import script\n",
    "df_Site = pd.concat([\n",
    "    df_Site,\n",
    "    pd.DataFrame([['John Eric MacFarlane'], ['JA Coady']], columns=['site'])\n",
    "], axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf79cc",
   "metadata": {},
   "source": [
    "##### MORE COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466857c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adada9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb86008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34772e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108681e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a0548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae85f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aec79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379ecec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c97b2ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2ea92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d51dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc7656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b07219c5",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# SAVE DATA\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2074b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns for clarity - all flags at the end\n",
    "df_SD = df_SD[[x for x in list(df_SD.columns) if 'FLAG' not in str(x)] + [x for x in list(df_SD.columns) if 'FLAG' in str(x)]]\n",
    "df_FD = df_FD[[x for x in list(df_FD.columns) if 'FLAG' not in str(x)] + [x for x in list(df_FD.columns) if 'FLAG' in str(x)]]\n",
    "df_LF = df_LF[[x for x in list(df_LF.columns) if 'FLAG' not in str(x)] + [x for x in list(df_LF.columns) if 'FLAG' in str(x)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1faaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle files of dataframes\n",
    "if save_pickles := False:\n",
    "    df_SD.to_pickle('df_SD_cleaned.pickle')\n",
    "    df_FD.to_pickle('df_FD_cleaned.pickle')\n",
    "    df_LF.to_pickle('df_LF_cleaned.pickle')\n",
    "    df_LF_grouped.to_pickle('df_LF_grouped_cleaned.pickle')\n",
    "    df_Site.to_pickle('df_Site_cleaned.pickle')\n",
    "    df_TrapSupervisors.to_pickle('df_TrapSupervisors_cleaned.pickle')\n",
    "\n",
    "# save files to this workbook drive\n",
    "if save_csv := False:\n",
    "    df_SD.to_csv('gaspereau_sample_data_cleaned.csv', index=False)\n",
    "    df_FD.to_csv('gaspereau_fish_details_cleaned.csv', index=False)\n",
    "    df_LF.to_csv('gaspereau_length_frequencies_cleaned.csv', index=False)\n",
    "    df_Site.to_csv('gaspereau_sites_cleaned.csv', index=False)\n",
    "    df_TrapSupervisors.to_csv('gaspereau_trap_supervisors_cleaned.csv', index=False)\n",
    "    df_LF_grouped.to_csv('gaspereau_LF_grouped_cleaned.csv', index=False)\n",
    "    \n",
    "# upload to temp folder for import into Kevin's local dm_apps\n",
    "import_file_location = 'C:\\\\Users\\\\CARRK\\\\Documents\\\\Repositories\\\\dm_app_root\\\\dm_apps\\\\herring\\\\temp\\\\'\n",
    "\n",
    "if upload_csv_to_temp_folder := False:\n",
    "    df_SD.to_csv(import_file_location + 'gaspereau_sample_data.csv', index=False)\n",
    "    df_FD.to_csv(import_file_location + 'gaspereau_fish_details.csv', index=False)\n",
    "    df_Site.to_csv(import_file_location + 'gaspereau_sites.csv', index=False)\n",
    "    df_TrapSupervisors.to_csv(import_file_location + 'gaspereau_trap_supervisors.csv', index=False)\n",
    "    df_LF_grouped.to_csv(import_file_location + 'gaspereau_LF_grouped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd962771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fd065c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453a769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e90be9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef61c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c64c72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94f0b60e",
   "metadata": {},
   "source": [
    "# OLD STUFF - recheck later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22228e2",
   "metadata": {},
   "source": [
    "# Check Import Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "673a9487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkthese = [\n",
    "    1993052010, 1993053010, 2016053100, 2016061400, 2016062100, 2017053092, 2017060692, 2018052900, 2018060800, \n",
    "    2018062700, 2019060794, 2019060793, 2019061493, 2019062594, 1989060100, 1989060200, 1989060700, 2011060414, \n",
    "    2016053195, 2016061495, 2016062195, 2018052992, 2018062792, 2018060892, 2021052092, 2021060192, 2021060392, \n",
    "    2021061592, 2021062392\n",
    "]\n",
    "\n",
    "# these were rejected then recreated\n",
    "len(list(df_SD[df_SD.id.isin(checkthese)].id)), len(checkthese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "008cfdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', <NA>, 92, 94, 93, 14, 95], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why were they rejected\n",
    "df_SD[df_SD.id.isin(checkthese)].SITE1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "906e5819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, '1A', '1B', 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 17, 18, 19, 20, 21,\n",
       "       23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40,\n",
       "       41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59,\n",
       "       60, 61, 62, 63, 64, 65, 66, 67, 68, 'John Eric MacFarlane',\n",
       "       'JA Coady'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# none of the sites match\n",
    "df_Site.site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc04dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: if a site is unmatched, make it None, don't reject it\n",
    "# didn't happen, but similar for trap_supervisor not matching FK table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4a391",
   "metadata": {},
   "source": [
    "# After Import Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6765a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_FD = list(df_FD[df_FD.FLAG_MISNUMBERED_FISH_DETAILS==True].id.unique())\n",
    "rejected_SD = list(df_SD[df_SD.FLAG_DATETIME==True].id.unique())\n",
    "rejected_id = rejected_FD + rejected_SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaf7753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15467"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> CORRECT\n",
    "# how many total samples were imported?\n",
    "df_SD[df_SD.FLAG_DATETIME.isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bd751582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(916, 1156, 821)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about LF, FD, both?\n",
    "(\n",
    "    df_SD[(df_SD.FLAG_DATETIME.isnull()) & (df_SD.id.isin(df_LF.id.unique()))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_DATETIME.isnull()) & (df_SD.id.isin(df_FD.id.unique()))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_DATETIME.isnull()) & (df_SD.id.isin(df_LF.id.unique())) & (df_SD.id.isin(df_FD.id.unique()))].shape[0]\n",
    ")\n",
    "# -> 916, 1149, 803\n",
    "# yes, meh, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e3dd906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> CORRECT\n",
    "# why are we missing 7 FD? were they rejected?\n",
    "# -> YES, exactly 7 were rejected (invalid kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d596f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14216"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without any FD or LF?\n",
    "df_SD[~(df_SD.id.isin(df_LF.id.unique())) & ~(df_SD.id.isin(df_FD.id.unique())) & (df_SD.FLAG_DATETIME.isnull())].shape[0]\n",
    "# -> 14223\n",
    "# close, but how are there more in dm_apps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06c2d9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14222"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe the rejected FD were still imported\n",
    "rejected_FD = [2993252737, 2993252952, 2993260933, 2998250105, 3010252925, 3010250541, 3010261141] # all of these samples were imported as ghost samples\n",
    "df_SD[~(df_SD.id.isin(df_LF.id.unique())) & (~(df_SD.id.isin(df_FD.id.unique())) | df_SD.id.isin(rejected_FD)) & (df_SD.FLAG_DATETIME.isnull())].shape[0]\n",
    "# -> CORRECT (yuck code, but it matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "29a72753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>RIVER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>code</th>\n",
       "      <th>GEAR</th>\n",
       "      <th>SITE_NO</th>\n",
       "      <th>no_nets</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>Week</th>\n",
       "      <th>catch_lbs</th>\n",
       "      <th>catch_kg</th>\n",
       "      <th>hours_fished</th>\n",
       "      <th>zone</th>\n",
       "      <th>last_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>bycatch_sbass</th>\n",
       "      <th>bycatch_shad</th>\n",
       "      <th>bycatch_other</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>SITE1</th>\n",
       "      <th>SITE2</th>\n",
       "      <th>remarks</th>\n",
       "      <th>id</th>\n",
       "      <th>total_fish_preserved</th>\n",
       "      <th>total_fish_measured</th>\n",
       "      <th>AM_PM_PERIOD</th>\n",
       "      <th>wt_lbs</th>\n",
       "      <th>FLAG_DATETIME</th>\n",
       "      <th>FLAG_HOURS_FISHED</th>\n",
       "      <th>FLAG_SITE</th>\n",
       "      <th>FLAG_AM_PM_PERIOD_DISCREPANCIES</th>\n",
       "      <th>FLAG_GHOST_SAMPLE</th>\n",
       "      <th>FLAG_AMBIGUOUS_MATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7015.000</td>\n",
       "      <td>3182.000</td>\n",
       "      <td>13</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2988052348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4008.000</td>\n",
       "      <td>1818.000</td>\n",
       "      <td>13</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3988052348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6558</th>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>900.000</td>\n",
       "      <td>408.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>58</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2997061258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6559</th>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>200.000</td>\n",
       "      <td>90.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>58</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3997061258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9276</th>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Charles McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1150.000</td>\n",
       "      <td>521.600</td>\n",
       "      <td>15</td>\n",
       "      <td>lower</td>\n",
       "      <td>McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3004061001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9277</th>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Charles McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1125.000</td>\n",
       "      <td>510.300</td>\n",
       "      <td>6.5</td>\n",
       "      <td>lower</td>\n",
       "      <td>McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4004061001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATETIME  DIST   RIVER              NAME code   GEAR SITE_NO no_nets  \\\n",
       "2683 1988-05-23 2.000  SWMARG  Michael D Gillis  NaN 81.000      48     NaN   \n",
       "2684 1988-05-23 2.000  SWMARG  Michael D Gillis  NaN 81.000      48     NaN   \n",
       "6558 1997-06-12 2.000  SWMARG  Michael D Gillis  NaN 81.000      58       1   \n",
       "6559 1997-06-12 2.000  SWMARG  Michael D Gillis  NaN 81.000      58       1   \n",
       "9276 2004-06-10 2.000  SWMARG  Charles McDaniel  NaN 81.000       1       1   \n",
       "9277 2004-06-10 2.000  SWMARG  Charles McDaniel  NaN 81.000       1       1   \n",
       "\n",
       "      YEAR  MM  DD  Week  catch_lbs  catch_kg hours_fished   zone last_name  \\\n",
       "2683  1988   5  23  <NA>   7015.000  3182.000           13  upper    Gillis   \n",
       "2684  1988   5  23  <NA>   4008.000  1818.000           13  upper    Gillis   \n",
       "6558  1997   6  12     7    900.000   408.200          NaN  upper    Gillis   \n",
       "6559  1997   6  12     7    200.000    90.700          NaN  upper    Gillis   \n",
       "9276  2004   6  10     7   1150.000   521.600           15  lower  McDaniel   \n",
       "9277  2004   6  10     7   1125.000   510.300          6.5  lower  McDaniel   \n",
       "\n",
       "     comments  bycatch_sbass  bycatch_shad bycatch_other   DATETIME SITE1  \\\n",
       "2683      NaN            NaN           NaN           NaN 1988-05-23    48   \n",
       "2684      NaN            NaN           NaN           NaN 1988-05-23    48   \n",
       "6558      NaN            NaN           NaN           NaN 1997-06-12    58   \n",
       "6559      NaN            NaN           NaN           NaN 1997-06-12    58   \n",
       "9276      NaN            NaN           NaN           NaN 2004-06-10     1   \n",
       "9277      NaN            NaN           NaN           NaN 2004-06-10     1   \n",
       "\n",
       "     SITE2 remarks          id  total_fish_preserved  total_fish_measured  \\\n",
       "2683  <NA>     NaN  2988052348                   NaN                  NaN   \n",
       "2684  <NA>     NaN  3988052348                   NaN                  NaN   \n",
       "6558  <NA>     NaN  2997061258                   NaN                  NaN   \n",
       "6559  <NA>     NaN  3997061258                   NaN                  NaN   \n",
       "9276  <NA>     NaN  3004061001                   NaN                  NaN   \n",
       "9277  <NA>     NaN  4004061001                   NaN                  NaN   \n",
       "\n",
       "     AM_PM_PERIOD  wt_lbs FLAG_DATETIME FLAG_HOURS_FISHED FLAG_SITE  \\\n",
       "2683          NaN     NaN           NaN               NaN       NaN   \n",
       "2684          NaN     NaN           NaN               NaN       NaN   \n",
       "6558          NaN     NaN           NaN               NaN       NaN   \n",
       "6559          NaN     NaN           NaN               NaN       NaN   \n",
       "9276          NaN     NaN           NaN               NaN       NaN   \n",
       "9277          NaN     NaN           NaN               NaN       NaN   \n",
       "\n",
       "     FLAG_AM_PM_PERIOD_DISCREPANCIES FLAG_GHOST_SAMPLE FLAG_AMBIGUOUS_MATCH  \n",
       "2683                             NaN               NaN                  NaN  \n",
       "2684                             NaN               NaN                  NaN  \n",
       "6558                             NaN               NaN                  NaN  \n",
       "6559                             NaN               NaN                  NaN  \n",
       "9276                             NaN               NaN                  NaN  \n",
       "9277                             NaN               NaN                  NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> CORRECT\n",
    "# how many ambiguous samples?  6\n",
    "# do these match with FD or LF?  No. (correct)\n",
    "df_SD[~(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id > 2024000000) & (df_SD.FLAG_DATETIME.isnull())][['DATETIME']+list(df_SD.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4deb3009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 184, 241, 146)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> CORRECT\n",
    "# how many ghost sites? with LF? FD? both?\n",
    "(\n",
    "    df_SD[df_SD.FLAG_GHOST_SAMPLE == True].shape[0],\n",
    "    df_SD[(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id.isin(df_LF.id.unique()))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id.isin(df_FD.id.unique())) & ~(df_SD.id.isin(rejected_id))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id.isin(df_LF.id.unique())) & (df_SD.id.isin(df_FD.id.unique())) & ~(df_SD.id.isin(rejected_id))].shape[0]\n",
    ")\n",
    "# -> 303, 185, 241, 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
