{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e30e8b72",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# IMPORTS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b86bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.dataframe td { white-space: nowrap; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# no text wrapping\n",
    "display(HTML(\"<style>.dataframe td { white-space: nowrap; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b99b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframes\n",
    "df_SD = pd.read_pickle('df_SD.pickle')\n",
    "df_FD = pd.read_pickle('df_FD.pickle')\n",
    "df_LF = pd.read_pickle('df_LF.pickle')\n",
    "df_Site = pd.read_pickle('df_Site.pickle')\n",
    "df_TrapSupervisors = pd.read_pickle('df_TrapSupervisors.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3975904c",
   "metadata": {},
   "source": [
    "### Helper Function to UPDATE ID to Match Updated DATETIME and SITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "22e7c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_id(row):\n",
    "    \"\"\"only run before disambiguating month portion of ids for FD and LF\"\"\"\n",
    "    return str(row.id)[0:4] + str(row.DATETIME.month).rjust(2,'0') + str(row.DATETIME.day).rjust(2, '0') + str(row.SITE1).rjust(2, '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d8832f",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# FISH DETAILS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e121f",
   "metadata": {},
   "source": [
    "## Combine Age 2 and Age 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc43f74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if age2 and age3 occur at the same time\n",
    "(\n",
    "    df_FD[df_FD['Ager_2'].notnull() & df_FD['Ager_3'].notnull()].shape[0],\n",
    "    df_FD[df_FD['AGE_2'].notnull() & df_FD['AGE_3'].notnull()].shape[0],\n",
    "    df_FD[df_FD['FSP_2'].notnull() & df_FD['FSP_3'].notnull()].shape[0], \n",
    "    df_FD[df_FD['Comments_2'].notnull() & df_FD['Comments_3'].notnull()].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a465887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 2 columns\n",
    "df_FD[df_FD.Ager_2.notnull() | df_FD.AGE_2.notnull() | df_FD.FSP_2.notnull() | df_FD.Comments_2.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5656122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2339"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 3 columns\n",
    "df_FD[df_FD.Ager_3.notnull() | df_FD.AGE_3.notnull() | df_FD.FSP_3.notnull() | df_FD.Comments_3.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7b31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine aging 2 and aging 3 into one set of data\n",
    "df_FD['Ager_2'] = df_FD['Ager_2'].fillna(df_FD['Ager_3'])\n",
    "df_FD['AGE_2'] = df_FD['AGE_2'].fillna(df_FD['AGE_3'])\n",
    "df_FD['FSP_2'] = df_FD['FSP_2'].fillna(df_FD['FSP_3'])\n",
    "df_FD['Comments_2'] = df_FD['Comments_2'].fillna(df_FD['Comments_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be03976a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 2 columns\n",
    "df_FD[df_FD.Ager_2.notnull() | df_FD.AGE_2.notnull() | df_FD.FSP_2.notnull() | df_FD.Comments_2.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6717dc86",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00e1023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if site is changed away from SITE1, update id to match\n",
    "\n",
    "# df_FD.loc[df_FD.FLAG_SITE==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e5739",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD: leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bcc7d",
   "metadata": {},
   "source": [
    "## FLAG_SEX: B and A? -> null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c65bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.FLAG_SEX==True, 'SEX'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fdb4666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'U', nan], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FD.loc[:, 'SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4317182",
   "metadata": {},
   "source": [
    "## FLAG_MATURITY: 44=4, 0=null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df0bc1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.MATURITY==44, 'MATURITY'] = 4\n",
    "df_FD.loc[df_FD.MATURITY==0, 'MATURITY'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd8a966",
   "metadata": {},
   "source": [
    "## FLAG_FSP_1: 33=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "466cbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.FSP_1==33, 'FSP_1'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873989fb",
   "metadata": {},
   "source": [
    "## FLAG_FL_STD: 10x off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93b1563f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "34891   261.000\n",
       "34892   253.000\n",
       "34893   248.000\n",
       "34894   258.000\n",
       "34895   261.000\n",
       "          ...  \n",
       "35244   240.000\n",
       "35245   250.000\n",
       "35246   200.000\n",
       "35247   204.000\n",
       "35248   241.000\n",
       "Name: FL_STD, Length: 264, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.FLAG_FL_STD==True, 'FL_STD'] *= 10\n",
    "df_FD.loc[df_FD.FLAG_FL_STD==True, 'FL_STD']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d475cf0",
   "metadata": {},
   "source": [
    "## FLAG_FL_WET_FROZEN: 5 typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ca0ebd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FL_WET</th>\n",
       "      <th>FL_FROZEN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35048</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35161</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35241</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35246</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35247</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       FL_WET  FL_FROZEN\n",
       "index                   \n",
       "35048    <NA>       <NA>\n",
       "35161    <NA>       <NA>\n",
       "35241    <NA>       <NA>\n",
       "35246    <NA>       <NA>\n",
       "35247    <NA>       <NA>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.FLAG_FL_WET_FROZEN==True, ['FL_WET', 'FL_FROZEN']] = np.nan\n",
    "df_FD.loc[df_FD.FLAG_FL_WET_FROZEN==True, ['FL_WET', 'FL_FROZEN']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23cd7a",
   "metadata": {},
   "source": [
    "## FLAG_WEIGHT_OUTLIER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f865c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "718      519.000\n",
       "914      539.000\n",
       "1348     501.000\n",
       "1800     512.000\n",
       "5324     503.000\n",
       "34988   1934.000\n",
       "Name: WEIGHT, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FD.loc[df_FD.FLAG_WEIGHT_OUTLIER==True, 'WEIGHT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78cb6f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: WEIGHT, dtype: float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.WEIGHT>1000, 'WEIGHT'] = np.nan\n",
    "df_FD.loc[df_FD.WEIGHT>1000, 'WEIGHT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3f6bc",
   "metadata": {},
   "source": [
    "## FLAG_GONAD_OUTLIER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f458e672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "5590    NaN\n",
       "14050   NaN\n",
       "23051   NaN\n",
       "23498   NaN\n",
       "25251   NaN\n",
       "26652   NaN\n",
       "32829   NaN\n",
       "Name: GONAD_WEIGHT, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_FD.loc[df_FD.FLAG_GONAD_OUTLIER==True, 'GONAD_WEIGHT'] = np.nan\n",
    "df_FD.loc[df_FD.FLAG_GONAD_OUTLIER==True, 'GONAD_WEIGHT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdb1883",
   "metadata": {},
   "source": [
    "## FLAG_MULTIPLE_SAMPLE_POSSIBILITIES and FLAG_MISNUMBERED_FISH_DETAILS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1302a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_MULTIPLE_SAMPLE_POSSIBILITIES==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a0fb582a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_MISNUMBERED_FISH_DETAILS==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8fb32c",
   "metadata": {},
   "source": [
    "## FLAG_LEN_WT_RATIO_OUTLIER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bb7055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_LEN_WT_RATIO_OUTLIER==True, ['FL_STD', 'WEIGHT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebe772",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# LENGTH FREQUENCIES\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609f406",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b825f95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if site is changed away from SITE1, update id to match\n",
    "\n",
    "# df_LF.loc[df_LF.FLAG_SITE==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b544d26",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD: leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bc70a9",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# SAMPLES\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d407fa",
   "metadata": {},
   "source": [
    "## FLAG_DATETIME: null datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d4bd35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: if date is changed, update id to match\n",
    "\n",
    "# df_SD.loc[df_SD.FLAG_DATETIME==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d66316",
   "metadata": {},
   "source": [
    "## FLAG_HOURS_FISHED: hours_fished = \"maximum \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "250e0652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13695    18\n",
       "13705    18\n",
       "13715    18\n",
       "13725    18\n",
       "13736    18\n",
       "13740    18\n",
       "13748    18\n",
       "13757    18\n",
       "13777    18\n",
       "13780    18\n",
       "13793    18\n",
       "13810    18\n",
       "13823    18\n",
       "13827    18\n",
       "13840    18\n",
       "13856    18\n",
       "13874    18\n",
       "13886    18\n",
       "13893    18\n",
       "13908    18\n",
       "13921    18\n",
       "13925    18\n",
       "13944    18\n",
       "13958    18\n",
       "13961    18\n",
       "13973    18\n",
       "13992    18\n",
       "14002    18\n",
       "Name: hours_fished, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONFIRM\n",
    "df_SD.loc[df_SD.FLAG_HOURS_FISHED==True, 'hours_fished'] = 18\n",
    "df_SD.loc[df_SD.FLAG_HOURS_FISHED==True, 'hours_fished']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ce6f3",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "def530ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5982    1A,8\n",
       "5999    1A,8\n",
       "6006    1A,8\n",
       "6025    1A,8\n",
       "6036    1A,8\n",
       "6049    1A,8\n",
       "6064    1A,8\n",
       "6092    1A,8\n",
       "6106    1A,8\n",
       "6112    1A,8\n",
       "6118    1A,8\n",
       "6125    1A,8\n",
       "6130    1A,8\n",
       "6138    1A,8\n",
       "6153    1A,8\n",
       "6162    1A,8\n",
       "6193    1A,8\n",
       "6198    1A,8\n",
       "6208    1A,8\n",
       "6215    1A,8\n",
       "6230    1A,8\n",
       "6251    1A,8\n",
       "6256    1A,8\n",
       "Name: SITE_NO, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: if site is updated, update id to match\n",
    "\n",
    "# these are currently importing as 1A\n",
    "df_SD.loc[df_SD.FLAG_SITE==True, 'SITE_NO']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec34f58",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD_DISCREPANCIES: FD and LF inconsistent\n",
    "#### SAMPLES, LENGTH FREQUENCIES, and FISH DETAILS all flagged\n",
    "* The samples will be where the AM PM data will be stored, so they are the only updates needed, outside of ghost samples, which can be updated as information becomes available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cde8ed00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DIST</th>\n",
       "      <th>RIVER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>code</th>\n",
       "      <th>GEAR</th>\n",
       "      <th>SITE_NO</th>\n",
       "      <th>no_nets</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>Week</th>\n",
       "      <th>catch_lbs</th>\n",
       "      <th>catch_kg</th>\n",
       "      <th>hours_fished</th>\n",
       "      <th>zone</th>\n",
       "      <th>last_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>bycatch_sbass</th>\n",
       "      <th>bycatch_shad</th>\n",
       "      <th>bycatch_other</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>SITE1</th>\n",
       "      <th>SITE2</th>\n",
       "      <th>remarks</th>\n",
       "      <th>id</th>\n",
       "      <th>total_fish_preserved</th>\n",
       "      <th>total_fish_measured</th>\n",
       "      <th>AM_PM_PERIOD</th>\n",
       "      <th>wt_lbs</th>\n",
       "      <th>FLAG_DATETIME</th>\n",
       "      <th>FLAG_HOURS_FISHED</th>\n",
       "      <th>FLAG_SITE</th>\n",
       "      <th>FLAG_AM_PM_PERIOD_DISCREPANCIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5130</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Daniel Stewart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>1100.000</td>\n",
       "      <td>499.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper</td>\n",
       "      <td>STEWART</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993-05-13</td>\n",
       "      <td>33</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1993051333</td>\n",
       "      <td>34.000</td>\n",
       "      <td>210.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>115.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8200</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Pierre Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2001</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>500.000</td>\n",
       "      <td>226.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>lower</td>\n",
       "      <td>Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-06-15</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2001061526</td>\n",
       "      <td>51.000</td>\n",
       "      <td>283.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>136.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10211</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Pierre Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2007</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9600.000</td>\n",
       "      <td>4354.500</td>\n",
       "      <td>8</td>\n",
       "      <td>lower</td>\n",
       "      <td>Chiasson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007-06-02</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007060226</td>\n",
       "      <td>32.000</td>\n",
       "      <td>290.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>130.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13373</th>\n",
       "      <td>2</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Donelda M Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>450.000</td>\n",
       "      <td>204.100</td>\n",
       "      <td>7</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-06-10</td>\n",
       "      <td>47</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014061047</td>\n",
       "      <td>38.000</td>\n",
       "      <td>246.000</td>\n",
       "      <td>AM</td>\n",
       "      <td>89.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DIST   RIVER              NAME code  GEAR SITE_NO no_nets  YEAR  MM  \\\n",
       "5130      2  SWMARG    Daniel Stewart  NaN    81      33     NaN  1993   5   \n",
       "8200      2  SWMARG   Pierre Chiasson  NaN    81      26       1  2001   6   \n",
       "10211     2  SWMARG   Pierre Chiasson  NaN    81      26       1  2007   6   \n",
       "13373     2  SWMARG  Donelda M Gillis  NaN    81      47       1  2014   6   \n",
       "\n",
       "       DD  Week  catch_lbs  catch_kg hours_fished   zone last_name comments  \\\n",
       "5130   13     3   1100.000   499.000          NaN  upper   STEWART      NaN   \n",
       "8200   15     7    500.000   226.800          NaN  lower  Chiasson      NaN   \n",
       "10211   2     5   9600.000  4354.500            8  lower  Chiasson      NaN   \n",
       "13373  10     7    450.000   204.100            7  upper    Gillis      NaN   \n",
       "\n",
       "       bycatch_sbass  bycatch_shad bycatch_other   DATETIME  SITE1 SITE2  \\\n",
       "5130             NaN           NaN           NaN 1993-05-13     33  <NA>   \n",
       "8200             NaN           NaN           NaN 2001-06-15     26  <NA>   \n",
       "10211            NaN           NaN           NaN 2007-06-02     26  <NA>   \n",
       "13373            NaN           NaN           NaN 2014-06-10     47  <NA>   \n",
       "\n",
       "      remarks          id  total_fish_preserved  total_fish_measured  \\\n",
       "5130      NaN  1993051333                34.000              210.000   \n",
       "8200      NaN  2001061526                51.000              283.000   \n",
       "10211     NaN  2007060226                32.000              290.000   \n",
       "13373     NaN  2014061047                38.000              246.000   \n",
       "\n",
       "      AM_PM_PERIOD  wt_lbs FLAG_DATETIME FLAG_HOURS_FISHED FLAG_SITE  \\\n",
       "5130            AM 115.000           NaN               NaN       NaN   \n",
       "8200            AM 136.000           NaN               NaN       NaN   \n",
       "10211           AM 130.000           NaN               NaN       NaN   \n",
       "13373           AM  89.000           NaN               NaN       NaN   \n",
       "\n",
       "      FLAG_AM_PM_PERIOD_DISCREPANCIES  \n",
       "5130                             True  \n",
       "8200                             True  \n",
       "10211                            True  \n",
       "13373                            True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_SD.loc[df_SD.FLAG_AM_PM_PERIOD_DISCREPANCIES==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2699c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_AM_PM_PERIOD_DISCREPANCIES==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "499e23b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LF.loc[df_LF.FLAG_AM_PM_PERIOD_DISCREPANCIES==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4395135c",
   "metadata": {},
   "source": [
    "## FLAG_NO_MATCHING_SAMPLE: no SAMPLE matching LF and/or FD\n",
    "* these will end up being matched with ghost samples (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d9f28eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_FD.loc[df_FD.FLAG_NO_MATCHING_SAMPLE==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96fb1058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_LF.loc[df_LF.FLAG_NO_MATCHING_SAMPLE==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaeebd6",
   "metadata": {},
   "source": [
    "## MAKE GHOST SAMPLES\n",
    "### for unmatched fish details and length frequencies\n",
    "### NOTE:\n",
    "Some ambiguous length frequencies and fish details match with eachother. However, we do not know which sample and length frequency are from the same sample. Therefore, we should make sure none of the ambiguous entries ever match automatically, and they are matched manually (eventually) in dm_apps, once that feature is implemented.\n",
    "\n",
    "Although there are no ambiguous samples that match with length frequencies or fish details, just for throroughness, we should revise id to avoid this possibility as well. \n",
    "\n",
    "Therefore, we will arbitrarily add 20 to months in ids of ambiguous fish details, and 40 to months in ids of ambiguous length frequencies. These numbers have no possibility to match a false positive, and they still uniquely identify their date and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a985a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to disambiguate ids, add 20 to all months for FD with id>2024000000, add 40 to all months for LF with id>2024000000\n",
    "\n",
    "# CONFIRM (period is not highly consistent, probably match, but left as False for now)\n",
    "if match_FD_LF_confirmed_using_period := False:  \n",
    "    # these are the only ambiguous fish details and length frequencies that appear to match after considering AM/PM period\n",
    "    matched_period = [3010051926, 4010051926, 3010052726, 4010052726]  # matched using period\n",
    "    df_FD.loc[(df_FD.id>2024000000) & (~df_FD.id.isin(matched_period)), 'id'] = df_FD.loc[df_FD.id>2024000000, 'id'] + 200000\n",
    "    df_LF.loc[(df_LF.id>2024000000) & (~df_LF.id.isin(matched_period)), 'id'] = df_LF.loc[df_LF.id>2024000000, 'id'] + 400000\n",
    "else:\n",
    "    df_FD.loc[df_FD.id>2024000000, 'id'] = df_FD.loc[df_FD.id>2024000000, 'id'] + 200000\n",
    "    df_LF.loc[df_LF.id>2024000000, 'id'] = df_LF.loc[df_LF.id>2024000000, 'id'] + 400000\n",
    "\n",
    "# verified samples are all sample ids before creating ghost samples\n",
    "verified_samples = set(df_SD.id)\n",
    "\n",
    "# add null samples where no match exists - Fish Details\n",
    "df_SD = pd.concat([\n",
    "    df_SD, \n",
    "    df_FD[~df_FD.id.isin(df_SD.id)].drop_duplicates('id')[['id', 'DATETIME', 'SITE1']]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# add null samples where no match exists - Length Frequencies\n",
    "df_SD = pd.concat([\n",
    "    df_SD, \n",
    "    df_LF[~df_LF.id.isin(df_SD.id)].drop_duplicates('id')[['id', 'DATETIME', 'SITE1']]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# add a Flag to indicate ghost samples for import\n",
    "df_SD.loc[~df_SD.id.isin(verified_samples), 'FLAG_GHOST_SAMPLE'] = True\n",
    "\n",
    "# add remarks\n",
    "df_SD.loc[~df_SD.id.isin(verified_samples), 'remarks'] = 'GHOST SAMPLE, created to match with unmatched Fish Details and/or Length Frequencies'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acb08e",
   "metadata": {},
   "source": [
    "## REMERGE JOINED DATA\n",
    "(previously merged without ghost samples, remerge with ghost data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c25f0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop previously merged columns (to be re-merged)\n",
    "df_SD = df_SD.drop(['total_fish_preserved', 'total_fish_measured', 'AM_PM_PERIOD', 'wt_lbs'], axis=1)\n",
    "\n",
    "# JOIN with Fish Details table to get total_fish_preserved\n",
    "# NOTE: this is an estimate, assuming all fish details are accounted for. This is the best information available\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    pd.merge(df_SD, df_FD, on='id').groupby('id').count()['FISH_NO'].reset_index(),\n",
    "    on='id',\n",
    "    how='left'\n",
    ").rename({'FISH_NO':'total_fish_preserved'}, axis=1)\n",
    "\n",
    "# JOIN with Length Frequencies table to get total_fish_measured\n",
    "# NOTE: this is an estimate, assuming all length frequencies are accounted for. This is the best information available\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    pd.merge(df_SD, df_LF, on='id').groupby('id').sum()['freq'].reset_index(),\n",
    "    on='id',\n",
    "    how='left'\n",
    ").rename({'freq':'total_fish_measured'}, axis=1)\n",
    "\n",
    "# # JOIN with Fish Details and Length Frequencies to get AM_PM_PERIOD \n",
    "# # NOTE: discrepancies flagged between Length Frequencies and Fish Details\n",
    "df_period = pd.merge(\n",
    "    df_FD[df_FD.PERIOD.notnull()].groupby('id').first().reset_index()[['id', 'PERIOD']],\n",
    "    df_LF[df_LF.period.notnull()].groupby('id').first().reset_index()[['id', 'period']], \n",
    "    on='id',\n",
    "    how='outer'\n",
    ")\n",
    "df_period['AM_PM_PERIOD'] = df_period['PERIOD'].fillna(df_period['period'])\n",
    "\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    df_period[['id', 'AM_PM_PERIOD']],\n",
    "    on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# JOIN with Length Frequency table to get sample weight\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    df_LF[['id', 'wt_lbs']],\n",
    "    on='id', \n",
    "    how='left'  # all samples \n",
    ").drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931fc791",
   "metadata": {},
   "source": [
    "# Fix Datetime Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f1d4ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some times merged into DATETIME from other df via ghost samples () \n",
    "# reduce to date and AM / PM period\n",
    "df_SD['DATETIME'] = pd.to_datetime(df_SD['DATETIME'].dt.date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e181a0",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# LF Grouped\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121c4a2",
   "metadata": {},
   "source": [
    "## Recreate df_LF_grouped with new ambiguous ids for LF entries (+40 to month if ambiguous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c5237e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by length bins, include only imported columns \n",
    "df_LF_grouped = df_LF.groupby(['id', 'length_bin_id']).sum('freq').reset_index()[['freq', 'length_bin_id', 'id']].rename({\n",
    "    'freq': 'count', \n",
    "    'length_bin_id': 'length_bin_id', \n",
    "    'id': 'sample_id'\n",
    "}, axis=1).reset_index(drop=True)[['sample_id', 'length_bin_id', 'count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "78673ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ambiguous entries, month bit (+40 to disambiguate)\n",
    "min([int(str(x)[4:6]) for x in list(df_LF_grouped[df_LF_grouped.sample_id>2024000000].sample_id.unique())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fdd7984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular entries, month bit\n",
    "max([int(str(x)[4:6]) for x in list(df_LF_grouped[df_LF_grouped.sample_id<2024000000].sample_id.unique())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07219c5",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# SAVE DATA\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c2074b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns for clarity - all flags at the end\n",
    "df_SD = df_SD[[x for x in list(df_SD.columns) if 'FLAG' not in str(x)] + [x for x in list(df_SD.columns) if 'FLAG' in str(x)]]\n",
    "df_FD = df_FD[[x for x in list(df_FD.columns) if 'FLAG' not in str(x)] + [x for x in list(df_FD.columns) if 'FLAG' in str(x)]]\n",
    "df_LF = df_LF[[x for x in list(df_LF.columns) if 'FLAG' not in str(x)] + [x for x in list(df_LF.columns) if 'FLAG' in str(x)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1faaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle files of dataframes\n",
    "if save_pickles := True:\n",
    "    df_SD.to_pickle('df_SD_cleaned.pickle')\n",
    "    df_FD.to_pickle('df_FD_cleaned.pickle')\n",
    "    df_LF.to_pickle('df_LF_cleaned.pickle')\n",
    "    df_LF_grouped.to_pickle('df_LF_grouped_cleaned.pickle')\n",
    "    df_Site.to_pickle('df_Site_cleaned.pickle')\n",
    "    df_TrapSupervisors.to_pickle('df_TrapSupervisors_cleaned.pickle')\n",
    "\n",
    "# save files to this workbook drive\n",
    "if save_csv := False:\n",
    "    df_SD.to_csv('gaspereau_sample_data_cleaned.csv', index=False)\n",
    "    df_FD.to_csv('gaspereau_fish_details_cleaned.csv', index=False)\n",
    "    df_LF.to_csv('gaspereau_length_frequencies_cleaned.csv', index=False)\n",
    "    df_Site.to_csv('gaspereau_sites_cleaned.csv', index=False)\n",
    "    df_TrapSupervisors.to_csv('gaspereau_trap_supervisors_cleaned.csv', index=False)\n",
    "    df_LF_grouped.to_csv('gaspereau_LF_grouped_cleaned.csv', index=False)\n",
    "    \n",
    "# upload to temp folder for import into Kevin's local dm_apps\n",
    "import_file_location = 'C:\\\\Users\\\\CARRK\\\\Documents\\\\Repositories\\\\dm_app_root\\\\dm_apps\\\\herring\\\\temp\\\\'\n",
    "\n",
    "if upload_csv_to_temp_folder := True:\n",
    "    df_SD.to_csv(import_file_location + 'gaspereau_sample_data.csv', index=False)\n",
    "    df_FD.to_csv(import_file_location + 'gaspereau_fish_details.csv', index=False)\n",
    "    df_Site.to_csv(import_file_location + 'gaspereau_sites.csv', index=False)\n",
    "    df_TrapSupervisors.to_csv(import_file_location + 'gaspereau_trap_supervisors.csv', index=False)\n",
    "    df_LF_grouped.to_csv(import_file_location + 'gaspereau_LF_grouped.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22228e2",
   "metadata": {},
   "source": [
    "# Check Import Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "673a9487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 29)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkthese = [\n",
    "    1993052010, 1993053010, 2016053100, 2016061400, 2016062100, 2017053092, 2017060692, 2018052900, 2018060800, \n",
    "    2018062700, 2019060794, 2019060793, 2019061493, 2019062594, 1989060100, 1989060200, 1989060700, 2011060414, \n",
    "    2016053195, 2016061495, 2016062195, 2018052992, 2018062792, 2018060892, 2021052092, 2021060192, 2021060392, \n",
    "    2021061592, 2021062392\n",
    "]\n",
    "\n",
    "# these were rejected then recreated\n",
    "len(list(df_SD[df_SD.id.isin(checkthese)].id)), len(checkthese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "008cfdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<NA>, 14, 95, 92, 93, 94, '10'], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why were they rejected\n",
    "df_SD[df_SD.id.isin(checkthese)].SITE1.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "906e5819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, '1A', '1B', 2, 4, 5, 6, 7, 8, 9, 11, 12, 15, 17, 18, 19, 20, 21,\n",
       "       23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40,\n",
       "       41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59,\n",
       "       60, 61, 62, 63, 64, 65, 66, 67, 68], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# none of the sites match\n",
    "df_Site.site.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fc04dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: if a site is unmatched, make it None, don't reject it\n",
    "# didn't happen, but similar for trap_supervisor not matching FK table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d4a391",
   "metadata": {},
   "source": [
    "# After Import Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6765a969",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected_FD = list(df_FD[df_FD.FLAG_MISNUMBERED_FISH_DETAILS==True].id.unique())\n",
    "rejected_SD = list(df_SD[df_SD.FLAG_DATETIME==True].id.unique())\n",
    "rejected_id = rejected_FD + rejected_SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eaf7753c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15485"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> CORRECT\n",
    "# how many total samples were imported?\n",
    "df_SD[df_SD.FLAG_DATETIME.isnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd751582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(916, 1156, 803)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what about LF, FD, both?\n",
    "(\n",
    "    df_SD[(df_SD.FLAG_DATETIME.isnull()) & (df_SD.id.isin(df_LF.id.unique()))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_DATETIME.isnull()) & (df_SD.id.isin(df_FD.id.unique()))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_DATETIME.isnull()) & (df_SD.id.isin(df_LF.id.unique())) & (df_SD.id.isin(df_FD.id.unique()))].shape[0]\n",
    ")\n",
    "# -> 916, 1149, 803\n",
    "# yes, meh, yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -> CORRECT\n",
    "# why are we missing 7 FD? were they rejected?\n",
    "# -> YES, exactly 7 were rejected (invalid kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d596f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14216"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# without any FD or LF?\n",
    "df_SD[~(df_SD.id.isin(df_LF.id.unique())) & ~(df_SD.id.isin(df_FD.id.unique())) & (df_SD.FLAG_DATETIME.isnull())].shape[0]\n",
    "# -> 14223\n",
    "# close, but how are there more in dm_apps?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06c2d9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14223"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maybe the rejected FD were still imported\n",
    "rejected_FD = [2993252737, 2993252952, 2993260933, 2998250105, 3010252925, 3010250541, 3010261141] # all of these samples were imported as ghost samples\n",
    "df_SD[~(df_SD.id.isin(df_LF.id.unique())) & (~(df_SD.id.isin(df_FD.id.unique())) | df_SD.id.isin(rejected_FD)) & (df_SD.FLAG_DATETIME.isnull())].shape[0]\n",
    "# -> CORRECT (yuck code, but it matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29a72753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>DIST</th>\n",
       "      <th>RIVER</th>\n",
       "      <th>NAME</th>\n",
       "      <th>code</th>\n",
       "      <th>GEAR</th>\n",
       "      <th>SITE_NO</th>\n",
       "      <th>no_nets</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MM</th>\n",
       "      <th>DD</th>\n",
       "      <th>Week</th>\n",
       "      <th>catch_lbs</th>\n",
       "      <th>catch_kg</th>\n",
       "      <th>hours_fished</th>\n",
       "      <th>zone</th>\n",
       "      <th>last_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>bycatch_sbass</th>\n",
       "      <th>bycatch_shad</th>\n",
       "      <th>bycatch_other</th>\n",
       "      <th>DATETIME</th>\n",
       "      <th>SITE1</th>\n",
       "      <th>SITE2</th>\n",
       "      <th>remarks</th>\n",
       "      <th>id</th>\n",
       "      <th>total_fish_preserved</th>\n",
       "      <th>total_fish_measured</th>\n",
       "      <th>AM_PM_PERIOD</th>\n",
       "      <th>wt_lbs</th>\n",
       "      <th>FLAG_DATETIME</th>\n",
       "      <th>FLAG_HOURS_FISHED</th>\n",
       "      <th>FLAG_SITE</th>\n",
       "      <th>FLAG_AM_PM_PERIOD_DISCREPANCIES</th>\n",
       "      <th>FLAG_GHOST_SAMPLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2452</th>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>7015.000</td>\n",
       "      <td>3182.000</td>\n",
       "      <td>13</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2988052348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>4008.000</td>\n",
       "      <td>1818.000</td>\n",
       "      <td>13</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1988-05-23</td>\n",
       "      <td>48</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3988052348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6514</th>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>900.000</td>\n",
       "      <td>408.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>58</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2997061258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6515</th>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Michael D Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>1997</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>200.000</td>\n",
       "      <td>90.700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>upper</td>\n",
       "      <td>Gillis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-06-12</td>\n",
       "      <td>58</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3997061258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9176</th>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Charles McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1150.000</td>\n",
       "      <td>521.600</td>\n",
       "      <td>15</td>\n",
       "      <td>lower</td>\n",
       "      <td>McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3004061001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9177</th>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>2.000</td>\n",
       "      <td>SWMARG</td>\n",
       "      <td>Charles McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2004</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1125.000</td>\n",
       "      <td>510.300</td>\n",
       "      <td>6.5</td>\n",
       "      <td>lower</td>\n",
       "      <td>McDaniel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-06-10</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4004061001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATETIME  DIST   RIVER              NAME code   GEAR SITE_NO no_nets  \\\n",
       "2452 1988-05-23 2.000  SWMARG  Michael D Gillis  NaN 81.000      48     NaN   \n",
       "2535 1988-05-23 2.000  SWMARG  Michael D Gillis  NaN 81.000      48     NaN   \n",
       "6514 1997-06-12 2.000  SWMARG  Michael D Gillis  NaN 81.000      58       1   \n",
       "6515 1997-06-12 2.000  SWMARG  Michael D Gillis  NaN 81.000      58       1   \n",
       "9176 2004-06-10 2.000  SWMARG  Charles McDaniel  NaN 81.000       1       1   \n",
       "9177 2004-06-10 2.000  SWMARG  Charles McDaniel  NaN 81.000       1       1   \n",
       "\n",
       "      YEAR  MM  DD  Week  catch_lbs  catch_kg hours_fished   zone last_name  \\\n",
       "2452  1988   5  23  <NA>   7015.000  3182.000           13  upper    Gillis   \n",
       "2535  1988   5  23  <NA>   4008.000  1818.000           13  upper    Gillis   \n",
       "6514  1997   6  12     7    900.000   408.200          NaN  upper    Gillis   \n",
       "6515  1997   6  12     7    200.000    90.700          NaN  upper    Gillis   \n",
       "9176  2004   6  10     7   1150.000   521.600           15  lower  McDaniel   \n",
       "9177  2004   6  10     7   1125.000   510.300          6.5  lower  McDaniel   \n",
       "\n",
       "     comments  bycatch_sbass  bycatch_shad bycatch_other   DATETIME SITE1  \\\n",
       "2452      NaN            NaN           NaN           NaN 1988-05-23    48   \n",
       "2535      NaN            NaN           NaN           NaN 1988-05-23    48   \n",
       "6514      NaN            NaN           NaN           NaN 1997-06-12    58   \n",
       "6515      NaN            NaN           NaN           NaN 1997-06-12    58   \n",
       "9176      NaN            NaN           NaN           NaN 2004-06-10     1   \n",
       "9177      NaN            NaN           NaN           NaN 2004-06-10     1   \n",
       "\n",
       "     SITE2 remarks          id  total_fish_preserved  total_fish_measured  \\\n",
       "2452  <NA>     NaN  2988052348                   NaN                  NaN   \n",
       "2535  <NA>     NaN  3988052348                   NaN                  NaN   \n",
       "6514  <NA>     NaN  2997061258                   NaN                  NaN   \n",
       "6515  <NA>     NaN  3997061258                   NaN                  NaN   \n",
       "9176  <NA>     NaN  3004061001                   NaN                  NaN   \n",
       "9177  <NA>     NaN  4004061001                   NaN                  NaN   \n",
       "\n",
       "     AM_PM_PERIOD  wt_lbs FLAG_DATETIME FLAG_HOURS_FISHED FLAG_SITE  \\\n",
       "2452          NaN     NaN           NaN               NaN       NaN   \n",
       "2535          NaN     NaN           NaN               NaN       NaN   \n",
       "6514          NaN     NaN           NaN               NaN       NaN   \n",
       "6515          NaN     NaN           NaN               NaN       NaN   \n",
       "9176          NaN     NaN           NaN               NaN       NaN   \n",
       "9177          NaN     NaN           NaN               NaN       NaN   \n",
       "\n",
       "     FLAG_AM_PM_PERIOD_DISCREPANCIES FLAG_GHOST_SAMPLE  \n",
       "2452                             NaN               NaN  \n",
       "2535                             NaN               NaN  \n",
       "6514                             NaN               NaN  \n",
       "6515                             NaN               NaN  \n",
       "9176                             NaN               NaN  \n",
       "9177                             NaN               NaN  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> CORRECT\n",
    "# how many ambiguous samples?  6\n",
    "# do these match with FD or LF?  No. (correct)\n",
    "df_SD[~(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id > 2024000000) & (df_SD.FLAG_DATETIME.isnull())][['DATETIME']+list(df_SD.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4deb3009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 185, 241, 130)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -> CORRECT\n",
    "# how many ghost sites? with LF? FD? both?\n",
    "(\n",
    "    df_SD[df_SD.FLAG_GHOST_SAMPLE == True].shape[0],\n",
    "    df_SD[(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id.isin(df_LF.id.unique()))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id.isin(df_FD.id.unique())) & ~(df_SD.id.isin(rejected_id))].shape[0],\n",
    "    df_SD[(df_SD.FLAG_GHOST_SAMPLE == True) & (df_SD.id.isin(df_LF.id.unique())) & (df_SD.id.isin(df_FD.id.unique())) & ~(df_SD.id.isin(rejected_id))].shape[0]\n",
    ")\n",
    "# -> 303, 185, 241, 130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9213bf03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
