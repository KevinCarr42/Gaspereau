{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185bd22f",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# IMPORTS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b86bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.dataframe td { white-space: nowrap; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# no text wrapping\n",
    "display(HTML(\"<style>.dataframe td { white-space: nowrap; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b99b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataframes\n",
    "df_SD = pd.read_pickle('df_SD.pickle')\n",
    "df_FD = pd.read_pickle('df_FD.pickle')\n",
    "df_LF = pd.read_pickle('df_LF.pickle')\n",
    "df_Site = pd.read_pickle('df_Site.pickle')\n",
    "df_TrapSupervisors = pd.read_pickle('df_TrapSupervisors.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8e28b6",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# FISH DETAILS\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e121f",
   "metadata": {},
   "source": [
    "## Combine Age 2 and Age 3 Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc43f74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if age2 and age3 occur at the same time\n",
    "(\n",
    "    df_FD[df_FD['Ager_2'].notnull() & df_FD['Ager_3'].notnull()].shape[0],\n",
    "    df_FD[df_FD['AGE_2'].notnull() & df_FD['AGE_3'].notnull()].shape[0],\n",
    "    df_FD[df_FD['FSP_2'].notnull() & df_FD['FSP_3'].notnull()].shape[0], \n",
    "    df_FD[df_FD['Comments_2'].notnull() & df_FD['Comments_3'].notnull()].shape[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a465887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 2 columns\n",
    "df_FD[df_FD.Ager_2.notnull() | df_FD.AGE_2.notnull() | df_FD.FSP_2.notnull() | df_FD.Comments_2.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5656122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2339"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 3 columns\n",
    "df_FD[df_FD.Ager_3.notnull() | df_FD.AGE_3.notnull() | df_FD.FSP_3.notnull() | df_FD.Comments_3.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed7b31fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine aging 2 and aging 3 into one set of data\n",
    "df_FD['Ager_2'] = df_FD['Ager_2'].fillna(df_FD['Ager_3'])\n",
    "df_FD['AGE_2'] = df_FD['AGE_2'].fillna(df_FD['AGE_3'])\n",
    "df_FD['FSP_2'] = df_FD['FSP_2'].fillna(df_FD['FSP_3'])\n",
    "df_FD['Comments_2'] = df_FD['Comments_2'].fillna(df_FD['Comments_3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be03976a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4022"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many Ager 2 columns\n",
    "df_FD[df_FD.Ager_2.notnull() | df_FD.AGE_2.notnull() | df_FD.FSP_2.notnull() | df_FD.Comments_2.notnull()].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d3336",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d888d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "118bdf0f",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD: leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bcc7d",
   "metadata": {},
   "source": [
    "## FLAG_SEX: B and A? -> null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7c65bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.FLAG_SEX==True, 'SEX'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "02db88c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['F', 'M', 'U', nan], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_FD.loc[:, 'SEX'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab39aa8",
   "metadata": {},
   "source": [
    "## FLAG_MATURITY: 44=4, 0=null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c63548a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.MATURITY==44, 'MATURITY'] = 4\n",
    "df_FD.loc[df_FD.MATURITY==0, 'MATURITY'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ec2103",
   "metadata": {},
   "source": [
    "## FLAG_FSP_1: 33=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "466cbfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FD.loc[df_FD.FSP_1==33, 'FSP_1'] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bc807",
   "metadata": {},
   "source": [
    "## FLAG_FL_STD: 10x off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec01ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "267b3a7b",
   "metadata": {},
   "source": [
    "## FLAG_FL_WET_FROZEN: 5 typos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f711c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e979addd",
   "metadata": {},
   "source": [
    "## FLAG_WEIGHT_OUTLIER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea512c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c4487eb",
   "metadata": {},
   "source": [
    "## FLAG_GONAD_OUTLIERS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b19fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "417a899e",
   "metadata": {},
   "source": [
    "## FLAG_MULTIPLE_SAMPLE_POSSIBILITIES and FLAG_MISNUMBERED_FISH_DETAILS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4437db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39dbb525",
   "metadata": {},
   "source": [
    "## FLAG_LEN_WT_RATIO_OUTLIER: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7b9de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22a8242c",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# LENGTH FREQUENCIES\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069dd414",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825f95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1a4e284",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD: leave as is"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5018b57d",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# SAMPLES\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cccfa7",
   "metadata": {},
   "source": [
    "## FLAG_DATETIME: null datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e275cd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3b5014",
   "metadata": {},
   "source": [
    "## FLAG_HOURS_FISHED: hours_fished = \"maximum \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96603ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc2f13e3",
   "metadata": {},
   "source": [
    "## FLAG_SITE: ambiguous site data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e451bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9381131",
   "metadata": {},
   "source": [
    "## FLAG_AM_PM_PERIOD_DISCREPANCIES: FD and LF inconsistent\n",
    "#### SAMPLES, LENGTH FREQUENCIES, and FISH DETAILS all flagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e653880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfd0ef47",
   "metadata": {},
   "source": [
    "## FLAG_NO_MATCHING_SAMPLE: no SAMPLE matching LF and/or FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0154b1ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baaeebd6",
   "metadata": {},
   "source": [
    "## MAKE GHOST SAMPLES\n",
    "### for unmatched fish details and length frequencies\n",
    "### NOTE:\n",
    "Some ambiguous length frequencies and fish details match with eachother. However, we do not know which sample and length frequency are from the same sample. Therefore, we should make sure none of the ambiguous entries ever match automatically, and they are matched manually (eventually) in dm_apps, once that feature is implemented.\n",
    "\n",
    "Although there are no ambiguous samples that match with length frequencies or fish details, just for throroughness, we should revise id to avoid this possibility as well. \n",
    "\n",
    "Therefore, we will arbitrarily add 20 to months in ids of ambiguous fish details, and 40 to months in ids of ambiguous length frequencies. These numbers have no possibility to match a false positive, and they still uniquely identify their date and site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a985a2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## to disambiguate ids, add 20 to all months for FD with id>2024000000, add 40 to all months for LF with id>2024000000\n",
    "df_FD.loc[df_FD.id>2024000000, 'id'] = df_FD.loc[df_FD.id>2024000000, 'id'] + 200000\n",
    "df_LF.loc[df_LF.id>2024000000, 'id'] = df_LF.loc[df_LF.id>2024000000, 'id'] + 400000\n",
    "\n",
    "# verified samples are all sample ids before creating ghost samples\n",
    "verified_samples = set(df_SD.id)\n",
    "\n",
    "# add null samples where no match exists - Length Frequencies\n",
    "df_SD = pd.concat([\n",
    "    df_SD, \n",
    "    df_LF[~df_LF.id.isin(verified_samples)].drop_duplicates('id')[['id', 'DATETIME', 'SITE1']]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# add null samples where no match exists - Fish Details\n",
    "df_SD = pd.concat([\n",
    "    df_SD, \n",
    "    df_FD[~df_FD.id.isin(verified_samples)].drop_duplicates('id')[['id', 'DATETIME', 'SITE1']]\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# add a Flag to indicate ghost samples for import\n",
    "df_SD.loc[~df_SD.id.isin(verified_samples), 'FLAG_GHOST_SAMPLE'] = True\n",
    "\n",
    "# add remarks\n",
    "df_SD.loc[~df_SD.id.isin(verified_samples), 'remarks'] = 'GHOST SAMPLE, created to match with unmatched Fish Details and/or Length Frequencies'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11acb08e",
   "metadata": {},
   "source": [
    "## REMERGE JOINED DATA\n",
    "(previously merged without ghost samples, remerge with ghost data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c25f0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop previously merged columns (to be re-merged)\n",
    "df_SD = df_SD.drop(['total_fish_preserved', 'total_fish_measured', 'AM_PM_PERIOD', 'wt_lbs'], axis=1)\n",
    "\n",
    "# JOIN with Fish Details table to get total_fish_preserved\n",
    "# NOTE: this is an estimate, assuming all fish details are accounted for. This is the best information available\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    pd.merge(df_SD, df_FD, on='id').groupby('id').count()['FISH_NO'].reset_index(),\n",
    "    on='id',\n",
    "    how='left'\n",
    ").rename({'FISH_NO':'total_fish_preserved'}, axis=1)\n",
    "\n",
    "# JOIN with Length Frequencies table to get total_fish_measured\n",
    "# NOTE: this is an estimate, assuming all length frequencies are accounted for. This is the best information available\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    pd.merge(df_SD, df_LF, on='id').groupby('id').sum()['freq'].reset_index(),\n",
    "    on='id',\n",
    "    how='left'\n",
    ").rename({'freq':'total_fish_measured'}, axis=1)\n",
    "\n",
    "# # JOIN with Fish Details and Length Frequencies to get AM_PM_PERIOD \n",
    "# # NOTE: discrepancies flagged between Length Frequencies and Fish Details\n",
    "df_period = pd.merge(\n",
    "    df_FD[df_FD.PERIOD.notnull()].groupby('id').first().reset_index()[['id', 'PERIOD']],\n",
    "    df_LF[df_LF.period.notnull()].groupby('id').first().reset_index()[['id', 'period']], \n",
    "    on='id',\n",
    "    how='outer'\n",
    ")\n",
    "df_period['AM_PM_PERIOD'] = df_period['PERIOD'].fillna(df_period['period'])\n",
    "\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    df_period[['id', 'AM_PM_PERIOD']],\n",
    "    on='id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# JOIN with Length Frequency table to get sample weight\n",
    "df_SD = pd.merge(\n",
    "    df_SD, \n",
    "    df_LF[['id', 'wt_lbs']],\n",
    "    on='id', \n",
    "    how='left'  # all samples \n",
    ").drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cdaff6",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# LF Grouped\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7048144",
   "metadata": {},
   "source": [
    "## Recreate df_LF_grouped with new ghost ids for LF entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "293f42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by length bins, include only imported columns \n",
    "df_LF_grouped = df_LF.groupby(['id', 'length_bin_id']).sum('freq').reset_index()[['freq', 'length_bin_id', 'id']].rename({\n",
    "    'freq': 'count', \n",
    "    'length_bin_id': 'length_bin_id', \n",
    "    'id': 'sample_id'\n",
    "}, axis=1).reset_index(drop=True)[['sample_id', 'length_bin_id', 'count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07219c5",
   "metadata": {},
   "source": [
    "#  ==================================\n",
    "# SAVE DATA\n",
    "#  =================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2074b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns for clarity - all flags at the end\n",
    "df_SD = df_SD[[x for x in list(df_SD.columns) if 'FLAG' not in str(x)] + [x for x in list(df_SD.columns) if 'FLAG' in str(x)]]\n",
    "df_FD = df_FD[[x for x in list(df_FD.columns) if 'FLAG' not in str(x)] + [x for x in list(df_FD.columns) if 'FLAG' in str(x)]]\n",
    "df_LF = df_LF[[x for x in list(df_LF.columns) if 'FLAG' not in str(x)] + [x for x in list(df_LF.columns) if 'FLAG' in str(x)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1faaaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle files of dataframes\n",
    "if save_pickles := False:\n",
    "    df_SD.to_pickle('df_SD.pickle')\n",
    "    df_FD.to_pickle('df_FD.pickle')\n",
    "    df_LF.to_pickle('df_LF.pickle')\n",
    "    df_LF_grouped.to_pickle('df_LF_grouped.pickle')\n",
    "    df_Site.to_pickle('df_Site.pickle')\n",
    "    df_TrapSupervisors.to_pickle('df_TrapSupervisors.pickle')\n",
    "\n",
    "# save files to this workbook drive\n",
    "if save_csv := False:\n",
    "    df_SD.to_csv('gaspereau_sample_data.csv', index=False)\n",
    "    df_FD.to_csv('gaspereau_fish_details.csv', index=False)\n",
    "    df_LF.to_csv('gaspereau_length_frequencies.csv', index=False)\n",
    "    df_Site.to_csv('gaspereau_sites.csv', index=False)\n",
    "    df_TrapSupervisors.to_csv('gaspereau_trap_supervisors.csv', index=False)\n",
    "    df_LF_grouped.to_csv('gaspereau_LF_grouped.csv', index=False)\n",
    "    \n",
    "# upload to temp folder for import into Kevin's local dm_apps\n",
    "import_file_location = 'C:\\\\Users\\\\CARRK\\\\Documents\\\\Repositories\\\\dm_app_root\\\\dm_apps\\\\herring\\\\temp\\\\'\n",
    "\n",
    "if upload_csv_to_temp_folder := False:\n",
    "    df_SD.to_csv(import_file_location + 'gaspereau_sample_data.csv', index=False)\n",
    "    df_FD.to_csv(import_file_location + 'gaspereau_fish_details.csv', index=False)\n",
    "    df_Site.to_csv(import_file_location + 'gaspereau_sites.csv', index=False)\n",
    "    df_TrapSupervisors.to_csv(import_file_location + 'gaspereau_trap_supervisors.csv', index=False)\n",
    "    df_LF_grouped.to_csv(import_file_location + 'gaspereau_LF_grouped.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
